# ðŸ› ï¸ GuÃ­a TÃ©cnica de AdministraciÃ³n - MeXa

## ðŸ“‹ Resumen Ejecutivo

MeXa es un sistema de orquestaciÃ³n de web scraping que coordina mÃºltiples mÃ³dulos independientes para extraer datos de Farfetch. Utiliza una arquitectura de microservicios con comunicaciÃ³n HTTP/REST y almacenamiento distribuido en MinIO.

## ðŸ—ï¸ Arquitectura del Sistema

### Componentes Principales

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ðŸŽ›ï¸ ORQUESTADOR PRINCIPAL                      â”‚
â”‚                   (Node.js - Puerto 3000)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ CoordinaciÃ³n de mÃ³dulos via HTTP REST API                â”‚
â”‚ â€¢ GestiÃ³n de flujos de trabajo con fallback automÃ¡tico     â”‚
â”‚ â€¢ Panel de administraciÃ³n web con SSE logs                 â”‚
â”‚ â€¢ API Gateway para servicios externos                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸŒ Browser-MCP  â”‚  ðŸ•·ï¸ Scraperr    â”‚  ðŸ¤– DeepScrape         â”‚
â”‚  (Puerto 3001)  â”‚  (Puerto 3002)  â”‚  (Puerto 3003)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Session mgmt  â”‚ â€¢ DOM parsing   â”‚ â€¢ ML-based element      â”‚
â”‚ â€¢ Cookie persistâ”‚ â€¢ CSS selectors â”‚   detection             â”‚
â”‚ â€¢ Fingerprintingâ”‚ â€¢ Pagination    â”‚ â€¢ Dynamic content       â”‚
â”‚ â€¢ Proxy rotationâ”‚ â€¢ Data extract  â”‚ â€¢ Semantic analysis     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ðŸ—„ï¸ MinIO STORAGE                         â”‚
â”‚                  S3-Compatible Object Store                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Bucket: mexa-data                                         â”‚
â”‚  â€¢ telegram/offers/     - Structured offer data           â”‚
â”‚  â€¢ telegram/users/      - User profiles & preferences     â”‚
â”‚  â€¢ scraping/           - Raw & processed scraping data    â”‚
â”‚  â€¢ sessions/           - Browser sessions & cookies       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ”§ ConfiguraciÃ³n del Sistema

### Variables de Entorno CrÃ­ticas

```bash
# Core Configuration
NODE_ENV=production|development
PORT=3000
LOG_LEVEL=info|debug|warn|error

# MinIO S3-Compatible Storage
MINIO_ENDPOINT=localhost
MINIO_PORT=9002
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin123
MINIO_BUCKET=mexa-data
MINIO_USE_SSL=false

# External Services Endpoints
BROWSER_MCP_URL=http://localhost:3001
SCRAPERR_URL=http://localhost:3002
DEEPSCRAPE_URL=http://localhost:3003

# Authentication Credentials
FF_EMAIL=your_farfetch_email@domain.com
FF_PASSWORD=your_secure_password

# Telegram Integration (Optional)
TELEGRAM_BOT_TOKEN=your_bot_token_from_botfather
TELEGRAM_CHAT_ID=your_chat_id_for_notifications
```

### InicializaciÃ³n de Servicios

```bash
# 1. MinIO Storage Service
docker run -d --name minio-mexa \
  -p 9002:9000 -p 9003:9001 \
  -e "MINIO_ROOT_USER=minioadmin" \
  -e "MINIO_ROOT_PASSWORD=minioadmin123" \
  -v /opt/mexa/data:/data \
  quay.io/minio/minio server /data --console-address ":9001"

# 2. Browser-MCP Service
cd external/browser-mcp
npm install && npm start

# 3. Scraperr Service  
cd external/scraperr
pip install -r requirements.txt && python app.py

# 4. DeepScrape Service
cd external/deepscrape
npm install && npm start

# 5. Main Orchestrator
npm install && npm run build && npm start
```

## ðŸ“Š Panel de AdministraciÃ³n

### Acceso y AutenticaciÃ³n

- **URL**: `http://localhost:3000/admin`
- **AutenticaciÃ³n**: Session-based (configurar en .env)
- **Roles**: Admin, Operator, Viewer

### Funcionalidades del Dashboard

#### 1. **Monitoreo en Tiempo Real**
- **Logs SSE Stream**: `/admin` â†’ pestaÃ±a "Logs"
- **MÃ©tricas de Sistema**: CPU, RAM, Network I/O
- **Estado de Servicios**: Health checks automÃ¡ticos cada 30s
- **Alertas**: Configurables por umbral y tipo de evento

#### 2. **GestiÃ³n de Workflows**
- **EjecuciÃ³n Manual**: Trigger de scraping bajo demanda
- **ProgramaciÃ³n**: Cron jobs para ejecuciÃ³n automÃ¡tica
- **Monitoreo**: Estado de workflows activos y histÃ³rico
- **ConfiguraciÃ³n**: ParÃ¡metros de timeout, reintentos, fallbacks

#### 3. **AdministraciÃ³n de Datos**
- **MinIO Browser**: Interfaz para explorar bucket `mexa-data`
- **Data Export**: Descarga de datasets en JSON/CSV
- **Cleanup**: Purga automÃ¡tica de datos antiguos
- **Backup**: ConfiguraciÃ³n de respaldos incrementales

## ðŸ” Sistema de Logs Avanzado

### ConfiguraciÃ³n del Logger

```typescript
interface LoggerConfig {
  maxLogs: 1000;           // Buffer circular en memoria
  retention: '7d';         // RetenciÃ³n en MinIO
  levels: ['debug', 'info', 'warn', 'error', 'fatal'];
  modules: [
    'Orchestrator',        // Core coordination logic
    'Browser-MCP',         // Session & authentication
    'Scraperr',           // Basic scraping operations
    'DeepScrape',         // AI-powered extraction
    'MinIO',              // Storage operations
    'Telegram Bot',       // Bot interactions
    'API Gateway',        // REST API requests
    'Workflow Engine'     // Job scheduling & execution
  ];
  filters: {
    performance: true,     // Log execution times
    errors: true,         // Stack traces
    security: true        // Auth attempts
  };
}
```

### AnÃ¡lisis de Logs

```bash
# Real-time monitoring
curl -N http://localhost:3000/api/logs?stream=true

# Filtered queries
curl "http://localhost:3000/api/logs?module=Scraperr&level=error&since=2024-01-01"

# Export for analysis
curl "http://localhost:3000/api/logs?format=csv" > logs_export.csv
```

## ðŸš€ Operaciones de Scraping

### Flujo de EjecuciÃ³n

```mermaid
sequenceDiagram
    participant A as Admin Panel
    participant O as Orchestrator
    participant B as Browser-MCP
    participant S as Scraperr
    participant D as DeepScrape
    participant M as MinIO
    
    A->>O: POST /api/scraping/start
    O->>M: Check session validity
    alt Session expired/invalid
        O->>B: POST /auth/login
        B->>B: Fingerprint + Proxy setup
        B->>M: Store session data
    end
    O->>S: POST /scrape with session
    alt Scraping successful
        S->>M: Store extracted data
    else Scraping failed
        O->>D: POST /resolve with AI
        D->>M: Store AI-extracted data
    end
    O->>A: Return results + metrics
```

### ConfiguraciÃ³n de Fallbacks

```typescript
const orchestrationConfig = {
  modules: {
    'browser-mcp': {
      timeout: 30000,      // 30s for auth operations
      retries: 2,
      healthCheck: '/health',
      priority: 1
    },
    'scraperr': {
      timeout: 15000,      // 15s for basic scraping
      retries: 3,
      healthCheck: '/status',
      priority: 2
    },
    'deepscrape': {
      timeout: 45000,      // 45s for AI processing
      retries: 1,
      healthCheck: '/ready',
      priority: 3
    }
  },
  fallbackStrategy: 'sequential', // sequential | parallel | weighted
  circuitBreaker: {
    failureThreshold: 5,
    resetTimeout: 60000
  }
};
```

## ðŸ—„ï¸ GestiÃ³n de Datos MinIO

### Estructura de Bucket

```
mexa-data/
â”œâ”€â”€ telegram/
â”‚   â”œâ”€â”€ offers/
â”‚   â”‚   â”œâ”€â”€ 2024-01-15/
â”‚   â”‚   â”‚   â”œâ”€â”€ offer-{uuid}.json
â”‚   â”‚   â”‚   â””â”€â”€ images/
â”‚   â”‚   â”‚       â””â”€â”€ {offer-id}-{index}.webp
â”‚   â”‚   â””â”€â”€ favorites/
â”‚   â”‚       â””â”€â”€ user-{chatId}.json
â”‚   â””â”€â”€ users/
â”‚       â””â”€â”€ {chatId}/
â”‚           â”œâ”€â”€ profile.json
â”‚           â”œâ”€â”€ filters.json
â”‚           â””â”€â”€ activity.json
â”œâ”€â”€ scraping/
â”‚   â”œâ”€â”€ sessions/
â”‚   â”‚   â””â”€â”€ {date}/
â”‚   â”‚       â”œâ”€â”€ raw-{timestamp}.ndjson
â”‚   â”‚       â”œâ”€â”€ processed-{timestamp}.json
â”‚   â”‚       â””â”€â”€ metadata.json
â”‚   â””â”€â”€ selectors/
â”‚       â”œâ”€â”€ current.json
â”‚       â””â”€â”€ history/
â”‚           â””â”€â”€ {date}-selectors.json
â””â”€â”€ sessions/
    â”œâ”€â”€ browser-mcp/
    â”‚   â””â”€â”€ {sessionId}.json
    â””â”€â”€ fingerprints/
        â””â”€â”€ active-{date}.json
```

### PolÃ­ticas de RetenciÃ³n

```json
{
  "retentionPolicies": {
    "telegram/offers": "30d",
    "telegram/users": "1y", 
    "scraping/sessions": "7d",
    "sessions/browser-mcp": "24h",
    "logs": "7d"
  },
  "compressionRules": {
    "*.json": "gzip",
    "*.ndjson": "lz4"
  },
  "backupSchedule": "0 2 * * *"
}
```

## ðŸ”’ Seguridad y Monitoreo

### MÃ©tricas de Rendimiento

- **Latencia de Scraping**: P50, P95, P99
- **Tasa de Ã‰xito**: Por mÃ³dulo y global
- **Throughput**: Ofertas procesadas por hora
- **Disponibilidad**: Uptime de servicios
- **Uso de Recursos**: CPU, RAM, Storage I/O

### Alertas Configurables

```yaml
alerts:
  - name: "High Error Rate"
    condition: "error_rate > 0.1"
    duration: "5m"
    action: "email,slack"
  
  - name: "Service Down"
    condition: "service_health == false"
    duration: "30s"
    action: "email,sms,restart"
  
  - name: "Storage Full"
    condition: "storage_usage > 0.9"
    duration: "1m"
    action: "cleanup,email"
```

## ðŸ› ï¸ Troubleshooting

### Problemas Comunes

1. **Servicios No Responden**
   ```bash
   # Check service status
   curl http://localhost:3001/health
   curl http://localhost:3002/status
   curl http://localhost:3003/ready
   
   # Restart services
   docker restart minio-mexa
   pm2 restart browser-mcp scraperr deepscrape
   ```

2. **MinIO Connection Issues**
   ```bash
   # Test connectivity
   mc alias set mexa-local http://localhost:9002 minioadmin minioadmin123
   mc ls mexa-local/mexa-data
   
   # Check bucket permissions
   mc policy get mexa-local/mexa-data
   ```

3. **High Memory Usage**
   ```bash
   # Monitor processes
   htop -p $(pgrep -f "node|python")
   
   # Clear logs buffer
   curl -X DELETE http://localhost:3000/api/logs
   ```

### Logs de DiagnÃ³stico

```bash
# Enable debug logging
export LOG_LEVEL=debug
npm restart

# Monitor specific module
curl -N "http://localhost:3000/api/logs?stream=true&module=Scraperr&level=debug"

# Export system state
curl http://localhost:3000/api/system/status > system_state.json
```
