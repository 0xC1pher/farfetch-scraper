# Plan de Mejoras para Hard Extraction en M贸dulos de Scraping

**Fecha:** 2025-07-16

Este documento detalla estrategias avanzadas para mejorar la extracci贸n de datos dif铆ciles (hard extraction) en los m贸dulos de scraping de MeXa, conservando la estructura de los schemas y los datos extra铆dos por cada m贸dulo. El objetivo es maximizar la cantidad y calidad de ofertas reales extra铆das, sin alterar el flujo ni la l贸gica general del sistema.
**IMPORTANTE**
* debemos validar las ofertas que no se repitan por modelos.
ejemplo, que no pueden repetirse los productos, y solo hay ofertas de la categoria woman, de , ni帽os (kids) y men, (hombres) no hay ofertas, debes asegurarte de traerte las ofertas reales

---

## ndice
1. [Browser-MCP](#browser-mcp)
2. [Scraperr](#scraperr)
3. [DeepScrape](#deepscrape)

---

## 1. Browser-MCP

**Funci贸n:** Scraping con navegador real, autenticaci贸n, gesti贸n de sesiones, fingerprints y proxies.

**Schema de datos:**
- Sesi贸n: `{ sessionId, cookies, localStorage, fingerprint, proxy, createdAt, lastUsed, isValid }`
- Extracci贸n: `{ action, email, sessionId, cookies, userAgent, fingerprint, proxy }`

**Estrategias propuestas:**
- Espera activa de carga de JS y recursos din谩micos (`waitForNetworkIdle`, `waitForSelector` avanzado).
- Simulaci贸n de scroll infinito y clics en "ver m谩s" para cargar todas las ofertas.
- Extracci贸n de datos embebidos en scripts (`application/ld+json`, JSON en DOM).
- Interceptaci贸n y an谩lisis de XHR/fetch para capturar datos de ofertas cargadas por AJAX.
- Rotaci贸n de fingerprints y proxies ya gestionada, pero a帽adir heur铆sticas para detectar bloqueos o respuestas parciales.
- Guardar HTML crudo de p谩ginas problem谩ticas para an谩lisis offline.

**Trackerlist de funciones a implementar:**
- [ ] Implementar espera activa de carga de JS y recursos din谩micos (`waitForNetworkIdle`, `waitForSelector` avanzado).
- [ ] Simular scroll infinito y clics en "ver m谩s" para cargar todas las ofertas reales.
- [ ] Extraer y parsear datos embebidos en scripts (`application/ld+json`, JSON en DOM).
- [ ] Interceptar y analizar XHR/fetch para capturar datos de ofertas cargadas por AJAX.
- [ ] A帽adir heur铆sticas para detectar bloqueos, respuestas parciales o p谩ginas incompletas.
- [ ] Guardar HTML crudo de p谩ginas problem谩ticas para an谩lisis offline.
- [ ] Validar que las im谩genes descargadas sean las reales de farfetch.com (no thumbnails ni placeholders).
- [ ] Validar que no se repitan productos por modelo y que se incluyan ofertas de todas las categor铆as disponibles (woman, men, kids).

---

##  Pasos detallados para implementar la espera avanzada de JS y recursos din谩micos (Browser-MCP)

1. **An谩lisis del flujo actual**
   - Revisar c贸mo y d贸nde se realiza la navegaci贸n y extracci贸n de datos en el m贸dulo Browser-MCP.
   - Identificar el punto exacto donde el navegador (Playwright/Puppeteer) navega a la URL objetivo y comienza la extracci贸n.

2. **Dise帽o de la funci贸n utilitaria**
   - Definir una funci贸n, por ejemplo, `waitForDynamicContent(page, selector, timeout)`.
   - Esta funci贸n debe:
     - Esperar a que la red est茅 ociosa (`networkidle`),
     - Esperar a que el selector clave est茅 presente y visible,
     - Permitir configurar el selector seg煤n el tipo de p谩gina/oferta.

3. **Integraci贸n en el flujo de scraping**
   - Llamar a la funci贸n utilitaria justo despu茅s de la navegaci贸n y antes de la extracci贸n de datos.
   - Asegurarse de que el selector usado corresponda a los contenedores de ofertas reales (por ejemplo, cards de producto en Farfetch).

4. **Validaci贸n y manejo de errores**
   - Si el selector no aparece en el tiempo esperado, registrar un log de advertencia y guardar el HTML crudo para an谩lisis offline.
   - Si la red no se estabiliza, intentar un reintento limitado antes de fallar.

5. **Configurabilidad y compatibilidad**
   - Permitir que el selector sea configurable por par谩metro o por tipo de scraping.
   - No modificar la estructura de los datos extra铆dos ni el contrato de la API.

6. **Pruebas y validaci贸n real**
   - Probar la funci贸n en escenarios reales de Farfetch (y otros sitios si aplica).
   - Validar que las ofertas extra铆das sean completas y que las im谩genes sean las reales.
   - Asegurarse de que no se repitan productos por modelo y que se cubran todas 
   - Verificar que no se altere el flujo ni la l贸gica general del sistema.

7. **Documentaci贸n y checklist**
   - Documentar el uso de la funci贸n y los par谩metros recomendados para cada tipo de p谩gina.
   - A帽adir un checklist de validaci贸n para asegurar que la funci贸n cumple con los objetivos (no mocks, datos reales, im谩genes reales, sin duplicados).

---

## 2. Scraperr

**Funci贸n:** Scraping alternativo, navegaci贸n r谩pida, extracci贸n de productos y ofertas.

**Schema de datos:**
- Extracci贸n: `{ selectors, items, itemCount, options, timestamp }`

**Estrategias propuestas:**
- Implementar fallback de selectores: probar m煤ltiples selectores alternativos si el principal falla.
- Simulaci贸n de eventos de usuario (scroll, clics, hover) para forzar la carga de nuevos elementos.
- Detecci贸n y extracci贸n de datos de scripts embebidos y endpoints internos (AJAX, fetch).
- Soporte para extracci贸n por lotes/paginaci贸n autom谩tica.
- Logs detallados de scraping para identificar en qu茅 paso se pierden ofertas.
- Guardar snapshots de HTML y respuestas XHR para debugging.

**Trackerlist de funciones a implementar:**
- [ ] Implementar fallback de selectores: probar m煤ltiples selectores alternativos si el principal falla.
- [ ] Simular eventos de usuario (scroll, clics, hover) para forzar la carga de nuevos elementos.
- [ ] Detectar y extraer datos de scripts embebidos y endpoints internos (AJAX, fetch).
- [ ] Soportar extracci贸n por lotes/paginaci贸n autom谩tica para obtener todas las ofertas.
- [ ] Agregar logs detallados de scraping para identificar en qu茅 paso se pierden ofertas.
- [ ] Guardar snapshots de HTML y respuestas XHR para debugging.
- [ ] Validar que las im谩genes descargadas sean las reales de farfetch.com.
- [ ] Validar unicidad de productos y cobertura de categor铆as (woman, men, kids).

---

## 3. DeepScrape

**Funci贸n:** Scraping profundo, extracci贸n sem谩ntica, fallback cuando los otros m贸dulos fallan.

**Schema de datos:**
- Extracci贸n: `{ elements, extractedData, extractedCount, depth, waitForSelector, timeout }`

**Estrategias propuestas:**
- Mejorar el uso de PlaywrightScraper para soportar acciones complejas (multi-scroll, espera de animaciones, etc.).
- Entrenamiento y ajuste del extractor LLM para identificar patrones de ofertas en layouts cambiantes.
- Extracci贸n sem谩ntica de precios, im谩genes y descripciones aunque cambien los selectores.
- An谩lisis de scripts y JSON embebido para obtener datos no visibles en el DOM.
- Guardar ejemplos de HTML y resultados de extracci贸n para retroalimentar el modelo.

**Trackerlist de funciones a implementar:**
- [ ] Mejorar PlaywrightScraper para soportar multi-scroll, espera de animaciones y carga din谩mica.
- [ ] Ajustar el extractor LLM para identificar patrones de ofertas en layouts cambiantes.
- [ ] Implementar extracci贸n sem谩ntica robusta de precios, im谩genes y descripciones aunque cambien los selectores.
- [ ] Analizar scripts y JSON embebido para obtener datos no visibles en el DOM.
- [ ] Guardar ejemplos de HTML y resultados de extracci贸n para retroalimentar el modelo.
- [ ] Validar que las im谩genes sean reales y que no haya duplicados de productos.
- [ ] Asegurar que se cubran todas las categor铆as de ofertas reales.

---

##  Reglas estrictas para la implementaci贸n de funciones avanzadas

- Solo se deben realizar las actividades documentadas en la secci贸n " Pasos detallados para implementar la espera avanzada de JS y recursos din谩micos (Browser-MCP)".
- Antes de comenzar cada actividad, se deben leer y repasar nuevamente estas reglas y la lista de tareas para asegurar que no se pierde el enfoque, la l贸gica ni el flujo del sistema.
- No se permite agregar, modificar o eliminar ninguna otra funcionalidad fuera de las actividades listadas.
- No se deben alterar los contratos de datos, la estructura de los schemas ni el flujo de orquestaci贸n.
- No se deben usar datos mock, pruebas artificiales ni im谩genes que no sean reales de la web objetivo.
- Cada avance debe ser validado contra estas reglas antes de continuar con la siguiente actividad.

---

## Consideraciones Generales
- **No modificar los schemas ni la estructura de datos:** Todas las mejoras deben respetar los contratos de datos actuales.
- **No alterar el flujo ni la l贸gica de orquestaci贸n:** Las estrategias se implementan solo dentro de los m贸dulos.
- **Solo datos reales:** Prohibido el uso de mocks, datos de test o informaci贸n ficticia en producci贸n.

---

**Siguiente paso:**
- Revisar y priorizar las estrategias propuestas por m贸dulo.
- Definir responsables y tiempos de implementaci贸n para cada t茅cnica.

---

*Documento generado autom谩ticamente para discusi贸n y planificaci贸n t茅cnica.*
